{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# policy gradient (part2: 训练agent)\n",
    "\n",
    "    TODO fix bug 重新训练\n",
    "    * 依然使用cross entropy loss， 末端依然使用softmax\n",
    "        但是对reward=-1的target，改变符号从而改变学习方向？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/playground/sgd_deep_learning/sgd_rl\n"
     ]
    }
   ],
   "source": [
    "# 环境配置\n",
    "%cd /playground/sgd_deep_learning/sgd_rl/go\n",
    "import sys\n",
    "sys.path.append('./python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dlgo import agent\n",
    "from dlgo import rl\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from dlgo.encoders import get_encoder_by_name\n",
    "from dlgo.networks import cnn_small, resnet18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file exists:  False\n",
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 数据 模型存放目录\n",
    "data_home_path = 'data/pg/'\n",
    "if not os.path.exists(data_home_path):\n",
    "    os.makedirs(data_home_path)\n",
    "\n",
    "class args:\n",
    "    learning_agent= data_home_path + 'agent_checkpoint.pth'\n",
    "    experience = [data_home_path + 'experience.pth'] # 训练数据可以保存在多个文件中，递归执行训练\n",
    "    agent_out = data_home_path + 'agent_checkpoint_update.pth'\n",
    "    \n",
    "    board_size = 9 # 缩小计算量, 保证算法的验证速度\n",
    "    num_games = 10 # 每轮迭代只收集10games的数据\n",
    "    lr=0.0001 # 学习率这么低吗？？\n",
    "    clipnorm=1.0\n",
    "    batch_size =512 # batch_size\n",
    "    \n",
    "# 全局变量\n",
    "global BOARD_SIZE\n",
    "BOARD_SIZE = args.board_size\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"model file exists: \", os.path.exists(args.learning_agent))\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1 batch_size 512\n",
      "iter: 2 batch_size 512\n",
      "iter: 3 batch_size 512\n",
      "iter: 4 batch_size 512\n",
      "iter: 5 batch_size 512\n",
      "iter: 6 batch_size 512\n",
      "iter: 7 batch_size 512\n",
      "iter: 8 batch_size 512\n",
      "iter: 9 batch_size 512\n",
      "iter: 10 batch_size 512\n",
      "iter: 11 batch_size 512\n",
      "iter: 12 batch_size 512\n",
      "iter: 13 batch_size 512\n",
      "iter: 14 batch_size 512\n",
      "iter: 15 batch_size 512\n",
      "iter: 16 batch_size 512\n",
      "iter: 17 batch_size 512\n",
      "iter: 18 batch_size 512\n",
      "iter: 19 batch_size 512\n",
      "iter: 20 batch_size 512\n",
      "iter: 21 batch_size 512\n",
      "iter: 22 batch_size 512\n",
      "iter: 23 batch_size 230\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    learning_agent_filename = args.learning_agent\n",
    "    updated_agent_filename = args.agent_out\n",
    "    \n",
    "    experience_files = args.experience\n",
    "    \n",
    "    learning_rate = args.lr\n",
    "    clipnorm = args.clipnorm\n",
    "    batch_size = args.batch_size\n",
    "    \n",
    "    # init agent object\n",
    "    encoder_name = 'sevenplane'\n",
    "    model = cnn_small(input_channel_num=7, board_size=BOARD_SIZE) \n",
    "\n",
    "    # 训练阶段只需要一个agent train self._model 即可\n",
    "    learning_agent = None\n",
    "    if not os.path.exists(learning_agent_filename): # check_point不存在\n",
    "        encoder = get_encoder_by_name(name=encoder_name, board_size=BOARD_SIZE)\n",
    "        learning_agent = agent.load_policy_agent(model=model, encoder=encoder, device=device)\n",
    "    else:\n",
    "        learning_agent = agent.load_policy_agent(model=model, save_path=learning_agent_filename, device=device)\n",
    "    assert learning_agent is not None\n",
    "\n",
    "    # 读取数据训练\n",
    "    for exp_filename in experience_files:\n",
    "        exp_buffer = rl.load_experience(exp_filename)\n",
    "        \n",
    "        learning_agent.train(\n",
    "            exp_buffer,\n",
    "            lr=learning_rate,\n",
    "            clipnorm=clipnorm,\n",
    "            batch_size=batch_size)\n",
    "\n",
    "    # 模型再保存\n",
    "    learning_agent.serialize(updated_agent_filename)\n",
    "\n",
    "    # todo \n",
    "    # 会产生一堆的checkpoint和 训练数据，这些文件保存的名字怎么选择\n",
    "    # 怎么自动的去迭代这个训练过程，非要人工介入的时候再暂停人工介入\n",
    "main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 3] <class 'numpy.ndarray'>\n",
      "0 <class 'numpy.int64'>\n",
      "2 <class 'numpy.int64'>\n",
      "1 <class 'numpy.int64'>\n",
      "3 <class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "candidates = np.arange(4)\n",
    "ranked_moves = np.random.choice(\n",
    "    candidates, len(candidates), replace=False)\n",
    "\n",
    "print(ranked_moves, type(ranked_moves))\n",
    "\n",
    "for point_idx in ranked_moves:\n",
    "    print(point_idx, type(point_idx))    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy(nn.Module):\n",
    "    def forward(self, y, labels):\n",
    "        y = y - y.max(dim=1, keepdim=True)[0] # 防止exp(x)数值溢出\n",
    "        logsumexp_y = torch.log(torch.exp(y).sum(dim=1, keepdim=True))\n",
    "        return torch.sum(logsumexp_y * labels) / y.shape[0] # labels is one hot (item can be -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 1, 0, 1])\n",
      "\n",
      "# loss只差一个负号\n",
      "tensor(0.5689, grad_fn=<DivBackward0>)\n",
      "tensor(-0.5689, grad_fn=<DivBackward0>)\n",
      "\n",
      "# 产生反向的梯度\n",
      "tensor([[ 0.0100, -0.0540,  0.0441],\n",
      "        [-0.0901,  0.0289,  0.0611],\n",
      "        [-0.0807,  0.0317,  0.0490],\n",
      "        [ 0.0237, -0.1020,  0.0783],\n",
      "        [ 0.0782, -0.1009,  0.0227]])\n",
      "tensor([[-0.0100,  0.0540, -0.0441],\n",
      "        [ 0.0901, -0.0289, -0.0611],\n",
      "        [ 0.0807, -0.0317, -0.0490],\n",
      "        [-0.0237,  0.1020, -0.0783],\n",
      "        [-0.0782,  0.1009, -0.0227]])\n",
      "grad 相加为:  tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "N = 5\n",
    "C = 3\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "ce = CrossEntropy()\n",
    "y = torch.randn((N, C), requires_grad=True) # 看看y这一步的梯度\n",
    "\n",
    "labels = torch.empty(N, dtype=torch.long).random_(0, C)\n",
    "one_hot_labels = F.one_hot(labels, C)\n",
    "\n",
    "print(labels)\n",
    "# print(one_hot_labels)\n",
    "# print(one_hot_labels*-1)\n",
    "\n",
    "# y.grad.zero_()\n",
    "loss1 = ce(y, one_hot_labels)\n",
    "loss1.backward()\n",
    "grad1 = y.grad.clone().detach()\n",
    "# print(grad1)\n",
    "\n",
    "y.grad.zero_()\n",
    "loss2 = ce(y, -1* one_hot_labels)\n",
    "loss2.backward()\n",
    "grad2 = y.grad.clone().detach()\n",
    "# print(grad2)\n",
    "\n",
    "\n",
    "print(\"\\n# loss只差一个负号\")\n",
    "print(loss1)\n",
    "print(loss2) \n",
    "\n",
    "print(\"\\n# 产生反向的梯度\")\n",
    "print(grad1)\n",
    "print(grad2) # \n",
    "print('grad 相加为: ', torch.sum(grad1+grad2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 1, 0, 0])\n",
      "torch.Size([5, 3]) tensor([[0, 0, 1],\n",
      "        [0, 0, 1],\n",
      "        [0, 1, 0],\n",
      "        [1, 0, 0],\n",
      "        [1, 0, 0]])\n",
      "tensor([[ 1],\n",
      "        [ 1],\n",
      "        [ 1],\n",
      "        [-1],\n",
      "        [-1]])\n",
      "torch.Size([5, 3]) tensor([[ 0,  0,  1],\n",
      "        [ 0,  0,  1],\n",
      "        [ 0,  1,  0],\n",
      "        [-1,  0,  0],\n",
      "        [-1,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "# 测试auto-broadcast\n",
    "th_actions = torch.empty(N, dtype=torch.long).random_(0, C)\n",
    "print(th_actions)\n",
    "\n",
    "th_one_hot_actions = F.one_hot(th_actions, C) # [B, num_class]\n",
    "print(th_one_hot_actions.shape, th_one_hot_actions)\n",
    "\n",
    "th_rewards = torch.tensor([1,1,1,-1,-1], dtype=torch.long).reshape(N, -1) # [B, 1]\n",
    "print(th_rewards)\n",
    "\n",
    "ys = th_one_hot_actions * th_rewards # auto-broadcast [B, num_class]\n",
    "print(ys.shape, ys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
