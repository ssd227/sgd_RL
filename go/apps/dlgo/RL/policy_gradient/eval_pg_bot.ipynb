{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# policy gradient (part3: 模型评估)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 环境配置\n",
    "%cd /playground/sgd_deep_learning/sgd_rl/go\n",
    "import sys\n",
    "sys.path.append('./python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import datetime\n",
    "from collections import namedtuple\n",
    "\n",
    "from dlgo import agent\n",
    "from dlgo import scoring\n",
    "from dlgo.goboard_fast import GameState, Player, Point\n",
    "from dlgo.networks import cnn_small, resnet18\n",
    "from dlgo.encoders import get_encoder_by_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    agent1='data/pg/agent_checkpoint_update.pth'\n",
    "    agent2='data/pg/agent_checkpoint_update.pth'\n",
    "    num_games=10\n",
    "    \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"model file exists: \", os.path.exists(args.agent1))\n",
    "print(\"model file exists: \", os.path.exists(args.agent2))\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOARD_SIZE = 9\n",
    "COLS = 'ABCDEFGHJKLMNOPQRST'\n",
    "STONE_TO_CHAR = {\n",
    "    None: '.',\n",
    "    Player.black: 'x',\n",
    "    Player.white: 'o',\n",
    "}\n",
    "\n",
    "def avg(items):\n",
    "    if not items:\n",
    "        return 0.0\n",
    "    return sum(items) / float(len(items))\n",
    "\n",
    "def print_board(board):\n",
    "    for row in range(BOARD_SIZE, 0, -1):\n",
    "        line = []\n",
    "        for col in range(1, BOARD_SIZE + 1):\n",
    "            stone = board.get(Point(row=row, col=col))\n",
    "            line.append(STONE_TO_CHAR[stone])\n",
    "        print('%2d %s' % (row, ''.join(line)))\n",
    "    print('   ' + COLS[:BOARD_SIZE])\n",
    "\n",
    "class GameRecord(namedtuple('GameRecord', 'moves winner margin')):\n",
    "    pass\n",
    "\n",
    "def name(player):\n",
    "    if player == Player.black:\n",
    "        return 'B'\n",
    "    return 'W'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_game(black_player, white_player):\n",
    "    moves = []\n",
    "    game = GameState.new_game(BOARD_SIZE)\n",
    "    agents = {\n",
    "        Player.black: black_player,\n",
    "        Player.white: white_player,\n",
    "    }\n",
    "    while not game.is_over():\n",
    "        next_move = agents[game.next_player].select_move(game)\n",
    "        moves.append(next_move)\n",
    "        #if next_move.is_pass:\n",
    "        #    print('%s passes' % name(game.next_player))\n",
    "        game = game.apply_move(next_move)\n",
    "\n",
    "    print_board(game.board)\n",
    "    game_result = scoring.compute_game_result(game)\n",
    "    print(game_result)\n",
    "\n",
    "    return GameRecord(\n",
    "        moves=moves,\n",
    "        winner=game_result.winner,\n",
    "        margin=game_result.winning_margin,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    encoder_name = 'sevenplane'\n",
    "    model = cnn_small(input_channel_num=7, board_size=BOARD_SIZE)\n",
    "    encoder = get_encoder_by_name(name=encoder_name, board_size=BOARD_SIZE)\n",
    "    \n",
    "    agent1 = agent.load_policy_agent(model=model, encoder=encoder, device=device)\n",
    "    # agent2 = agent.load_policy_agent(model=model, encoder=encoder, device=device)\n",
    "    \n",
    "    # agent1 = agent.load_policy_agent(model=model, save_path=args.agent1, device=device)\n",
    "    agent2 = agent.load_policy_agent(model=model, save_path=args.agent2, device=device)\n",
    "\n",
    "    wins = 0\n",
    "    losses = 0\n",
    "    color1 = Player.black\n",
    "    for i in range(args.num_games):\n",
    "        print('Simulating game %d/%d...' % (i + 1, args.num_games))\n",
    "        if color1 == Player.black:\n",
    "            black_player, white_player = agent1, agent2\n",
    "        else:\n",
    "            white_player, black_player = agent1, agent2\n",
    "        game_record = simulate_game(black_player, white_player)\n",
    "        if game_record.winner == color1:\n",
    "            wins += 1\n",
    "        else:\n",
    "            losses += 1\n",
    "        color1 = color1.other\n",
    "    print('Agent 1 record: %d/%d' % (wins, wins + losses))\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binomtest\n",
    "confidence = binomtest(60, 100, 0.5)\n",
    "print(confidence)\n",
    "print(confidence.pvalue)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for i in range(0,101):\n",
    "    x.append(i)\n",
    "    y.append(binomtest(i, 100, 0.5).pvalue)\n",
    "    # print(\"{}, {:.3f}\".format(i, binomtest(i, 100, 0.5).pvalue))\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 使用 Matplotlib 创建折线图\n",
    "plt.plot(x, y, label='折线图')  # 指定 x 和 y 值，可以添加标签\n",
    "\n",
    "# 添加标题和标签\n",
    "plt.title('confidence')\n",
    "plt.xlabel('X axis')\n",
    "plt.ylabel('Y axis')\n",
    "\n",
    "# 添加图例\n",
    "plt.legend()\n",
    "\n",
    "# 显示折线图\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def list_experience_files(data_dir):\n",
    "    files = []\n",
    "    base = data_dir + '*.pth'\n",
    "    for experience_file in glob.glob(base):\n",
    "        files.append(experience_file)                    \n",
    "    return files\n",
    "\n",
    "dir_path = \"/playground/sgd_deep_learning/sgd_rl/go/data/pg/experience/\"\n",
    "\n",
    "for x in list_experience_files(dir_path):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import uuid\n",
    "\n",
    "# 生成随机字符串作为文件名\n",
    "random_filename = str(uuid.uuid4())\n",
    "\n",
    "# 使用 hashlib 计算文件名的哈希值\n",
    "hash_object = hashlib.md5(random_filename.encode())\n",
    "hash_value = hash_object.hexdigest()\n",
    "\n",
    "print(hash_value, type(hash_value))\n",
    "\n",
    "# 使用哈希值作为文件名\n",
    "file_name = f\"{hash_value}.txt\"\n",
    "\n",
    "print(f\"随机文件名: {random_filename}\")\n",
    "print(f\"哈希值: {hash_value}\")\n",
    "print(f\"文件名: {file_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
