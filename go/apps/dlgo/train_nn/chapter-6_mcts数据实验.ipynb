{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCTS数据实验\n",
    "    由于mcts bot的搜索速度比较慢，通过训练NN_bot 可以快速由棋盘数据 预测 nextmove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 环境配置\n",
    "%cd /playground/sgd_deep_learning/sgd_rl/go\n",
    "import sys\n",
    "sys.path.append('./python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "# from dlgo.networks.resnet import\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "from dlgo.data import GoDataset\n",
    "from dlgo.script.generate_mcts_games import generate_game\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "# datatype = torch.bfloat16 # 节省内存但是计算太慢，？？？至少在cnn框架下不建议使用\n",
    "# datatype = torch.float32\n",
    "datatype = torch.float16"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step1: 准备mcts bot对局数据\n",
    "    * 蒙特卡洛搜索树模拟对局实在是太慢了\n",
    "    * 直接使用项目自带的数据 data/mcts_generated_games (训练集200 games，测试集20 games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用蒙特卡洛bot自我对局，收集监督训练的数据\n",
    "class args:    \n",
    "    board_size=9\n",
    "    rounds=1000\n",
    "    temperature=0.8\n",
    "    max_moves=60               \n",
    "    num_games=10\n",
    "    board_out = \"data/mcts/mini/\"\n",
    "    move_out = \"data/mcts/mini/\"\n",
    "\n",
    "def check_dir_exist(dir_path):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "check_dir_exist(args.board_out)\n",
    "check_dir_exist(args.move_out)\n",
    "    \n",
    "def main():\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    for i in range(args.num_games):\n",
    "        print('Generating game %d/%d...' % (i + 1, args.num_games))\n",
    "        x, y = generate_game(args.board_size, args.rounds, args.max_moves, args.temperature)\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "\n",
    "    x = np.concatenate(xs)\n",
    "    y = np.concatenate(ys)\n",
    "\n",
    "    np.save(args.board_out + 'features-{}.npy'.format(args.num_games), x)\n",
    "    np.save(args.move_out + 'labels-{}.npy'.format(args.num_games) , y)\n",
    "    \n",
    "# main() # mcts模拟对局太慢，暂不执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接调用已生成数据用于训练\n",
    "train_data_path = \"data/mcts_generated_games/features-200.npy\"\n",
    "test_data_path = \"data/mcts_generated_games/features-20.npy\"\n",
    "\n",
    "def load_dataset_with_tag(data_path, device):\n",
    "    features = np.load(data_path)\n",
    "    # print(features.shape)\n",
    "    labels = np.load(data_path.replace(\"features\", \"labels\"))\n",
    "    # np to tensor\n",
    "    x = torch.from_numpy(features).to(datatype).to(device=device).unsqueeze(dim=1)\n",
    "    y = torch.tensor(np.argmax(labels, axis=1), dtype=torch.long).to(device=device)\n",
    "    # wrap by Dataset\n",
    "    ds = TensorDataset(x, y)\n",
    "    return ds \n",
    "\n",
    "# tag 用于corss-entropy loss\n",
    "train_ds = load_dataset_with_tag(data_path=train_data_path, device=device)\n",
    "test_ds = load_dataset_with_tag(data_path=test_data_path, device=device)\n",
    "print(len(train_ds), len(test_ds))\n",
    "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=64, shuffle=True)\n",
    "\n",
    "for x, label in train_dl:\n",
    "    print(x.shape, label.shape)\n",
    "    break\n",
    "\n",
    "# def load_dataset_with_onehot(data_path, device):\n",
    "#     features = np.load(data_path)\n",
    "#     labels = np.load(data_path.replace(\"features\", \"labels\"))\n",
    "#     # np to tensor\n",
    "#     x = torch.from_numpy(features).to(datatype).to(device=device)\n",
    "#     y = torch.from_numpy(labels).to(torch.long).to(device=device)\n",
    "#     # wrap by Dataset\n",
    "#     ds = TensorDataset(x, y)\n",
    "#     return ds \n",
    "\n",
    "# # onehot 用于MSE-loss\n",
    "# train_ds_oh = load_dataset_with_onehot(data_path=train_data_path, device=device)\n",
    "# test_ds_oh = load_dataset_with_onehot(data_path=test_data_path, device=device)\n",
    "# train_dl_oh = DataLoader(train_ds_oh, batch_size=64, shuffle=True)\n",
    "# test_dl_oh = DataLoader(train_ds_oh, batch_size=64, shuffle=True)\n",
    "# for x, label in train_dl_oh:\n",
    "#     print(x.shape, label.shape)\n",
    "#     break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step2: FC_NN (move预测模型) with mse loss\n",
    "\n",
    "\"As you can see, the prediction accuracy of your\n",
    "experiment is at only around 2.3%, which isn’t satisfying\n",
    "at first sight. But recall that your baseline of\n",
    "randomly guessing moves is about 1.2%. This tells\n",
    "you that although the performance isn’t great,\n",
    "the model is learning and can predict moves better\n",
    "than random.\" -- P129 in book\n",
    "\n",
    "和实验数据大致吻合（只使用了200games做训练集，20games做测试集，比书中数据要少很多）\n",
    "\n",
    "        epoch:29, i:50/182, avg_loss:0.041\n",
    "        epoch:29, i:100/182, avg_loss:0.043\n",
    "        epoch:29, i:150/182, avg_loss:0.044\n",
    "        -----------------------------\n",
    "        Epoch 29: train_pred_succ:36.343%, 11705\n",
    "        Epoch 29: test_pred_succ:1.565%, 1214\n",
    "\n",
    "        best_epoch:10, best_test_pred:2.471%\n",
    "\n",
    "\n",
    "        使用dropout，效果略好\n",
    "        best_epoch:14, best_test_pred:2.636%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_model = nn.Sequential(*[\n",
    "    nn.Flatten(start_dim=1),\n",
    "    nn.Linear(9*9, 1000),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(1000, 500),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(500, 9*9),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_dataloader):\n",
    "    n_test = len(test_dataloader.dataset)\n",
    "    with torch.no_grad():\n",
    "        succ_num = 0\n",
    "        for x, label in test_dataloader:\n",
    "            y = model(x)\n",
    "            # y = torch.randn((x.shape[0], 81), device=device, dtype=datatype) # 测试随机有1.25%的正确率\n",
    "            # 计算预测正确概率\n",
    "            # print(type(y), y.shape, y)\n",
    "            predict = torch.argmax(y, dim=1)\n",
    "            # print(type(predict), predict.shape, predict)\n",
    "            # print(type(label),label.shape, label)\n",
    "            succ_num += torch.sum(predict == label)\n",
    "        return succ_num/n_test # 预测正确的概率 [瞎猜的概率1/9*9 = 12%]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, model, loss_fn, optimizer, epochs=3, test_dataloader=None):    \n",
    "    n_train = len(train_dataloader.dataset) # 总样本量\n",
    "    best_test_pred = 0\n",
    "    best_epoch = -1\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        acc_loss = 0\n",
    "        i = 0\n",
    "        n = 0\n",
    "        \n",
    "        for x, label in train_dataloader:\n",
    "            y = model(x)\n",
    "            loss = loss_fn(y, label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            acc_loss += loss.item()\n",
    "            n += x.shape[0]\n",
    "            i += 1\n",
    "            \n",
    "            if i%50==0:\n",
    "                print(\"epoch:{}, i:{}/{}, avg_loss:{:.3f}\"\n",
    "                      .format(epoch, i,\n",
    "                              n_train//x.shape[0],\n",
    "                              acc_loss/n,))\n",
    "\n",
    "        #########  end epoch  ###########\n",
    "        print(\"-----------------------------\")\n",
    "        # 训练集的准确率\n",
    "        train_succ_ratio = evaluate(model, train_dataloader) * 100\n",
    "        print(\"Epoch {}: train_pred_succ:{:.3f}%, {}\".format(epoch, train_succ_ratio, n_train))\n",
    "        \n",
    "        if test_dataloader:\n",
    "            n_test = len(test_dataloader.dataset) \n",
    "            test_succ_ratio = evaluate(model, test_dataloader) * 100\n",
    "            \n",
    "            if test_succ_ratio > best_test_pred:\n",
    "                best_test_pred = test_succ_ratio\n",
    "                best_epoch = epoch \n",
    "            \n",
    "            print(\"Epoch {}: test_pred_succ:{:.3f}%, {}\".format(epoch, test_succ_ratio, n_test))\n",
    "        else:\n",
    "            print(\"Epoch {0} complete\".format(epoch))\n",
    "            \n",
    "        print('\\n')\n",
    "        \n",
    "    \n",
    "    # 训练结束\n",
    "    print(\"best_epoch:{}, best_test_pred:{:.3f}%\".format(best_epoch, best_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fc_model.to(datatype).to(device)\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "optimizer = torch.optim.Adagrad(model.parameters()) # 还不错\n",
    "# optimizer = torch.optim.Adadelta(model.parameters()) # 也还行\n",
    "# optimizer = torch.optim.Adam(params=model.parameters(), lr=1) # 效果不好\n",
    "\n",
    "# 暂时注释掉\n",
    "# train(model=model,\n",
    "#       epochs=30,\n",
    "#       loss_fn=ce_loss,\n",
    "#       optimizer=optimizer,\n",
    "#       train_dataloader=train_dl,\n",
    "#       test_dataloader=test_dl,)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step3: 卷积模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = nn.Sequential(*[\n",
    "    nn.Conv2d(1, 48, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "    nn.BatchNorm2d(48),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    \n",
    "    nn.Conv2d(48, 48, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "    nn.BatchNorm2d(48),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2,),\n",
    "    nn.Dropout(p=0.5),\n",
    "    \n",
    "    nn.Flatten(start_dim=1),\n",
    "    nn.Linear(48*4*4, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(512, 9*9),\n",
    "    ])\n",
    "\n",
    "x = torch.randn(64,1,9,9)\n",
    "for layer in cnn_model:\n",
    "    print(layer)\n",
    "    x= layer(x)\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn_model.to(datatype).to(device)\n",
    "ce_loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "# optimizer = torch.optim.Adagrad(model.parameters()) # 还不错\n",
    "# optimizer = torch.optim.Adadelta(model.parameters()) # 也还行\n",
    "\n",
    "t1 = time.time()\n",
    "train(model=model,\n",
    "      epochs=30,\n",
    "      loss_fn=ce_loss,\n",
    "      optimizer=optimizer,\n",
    "      train_dataloader=train_dl,\n",
    "      test_dataloader=test_dl,)\n",
    "print('{:.3f}s'.format(time.time()-t1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、完全看不出来数据类型对CNN模型的加速效果，难道是由于计算密集型导致的模型数据类型影响不大？？\n",
    "\n",
    "    torch.float16  best_epoch:12, best_test_pred:2.883%, 20.8s  | best_epoch:21, best_test_pred:2.554%, 23.579s\n",
    "    torch.float32  best_epoch:19, best_test_pred:2.554%, 24.335s | best_epoch:15, best_test_pred:2.554%, 22.048s\n",
    "    torch.bfloat16 best_epoch:22, best_test_pred:2.636%, 75.696s |\n",
    "    注意混合精度训练非常慢(慢了3倍)，而且效果一般\n",
    "\n",
    "2、 少量的数据集合200，并不能在测试集合上达到书中描述的8%的预测准确性。   \n",
    "最好的模型在3.6%左右，确实比fc_nn好点（提升1个百分点）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(10,9,9)\n",
    "b= a.unsqueeze(dim=1)\n",
    "print(b.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
