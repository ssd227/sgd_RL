{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch model and training necessities\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Image datasets and image manipulation\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Image display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# In case you are using an environment that has TensorFlow installed,\n",
    "# such as Google Colab, uncomment the following code to avoid\n",
    "# a bug with saving embeddings to your TensorBoard directory\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import tensorboard as tb\n",
    "# tf.io.gfile = tb.compat.tensorflow_stub.io.gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gather datasets and prepare them for consumption\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Store separate training and validations splits in ./data\n",
    "training_set = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(training_set,\n",
    "                                              batch_size=4,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=2)\n",
    "\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set,\n",
    "                                                batch_size=4,\n",
    "                                                shuffle=False,\n",
    "                                                num_workers=2)\n",
    "\n",
    "# Class labels\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# Helper function for inline image display\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# Extract a batch of 4 images\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default log_dir argument is \"runs\" - but it's good to be specific\n",
    "# torch.utils.tensorboard.SummaryWriter is imported above\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')\n",
    "\n",
    "# Write image data to TensorBoard log dir\n",
    "writer.add_image('Four Fashion-MNIST Images', img_grid)\n",
    "writer.flush()\n",
    "\n",
    "# To view, start TensorBoard on the command line with:\n",
    "#   tensorboard --logdir=runs\n",
    "# ...and open a browser tab to http://localhost:6006/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "Batch 1000\n",
      "Batch 2000\n",
      "Batch 3000\n",
      "Batch 4000\n",
      "Batch 5000\n",
      "Batch 6000\n",
      "Batch 7000\n",
      "Batch 8000\n",
      "Batch 9000\n",
      "Batch 10000\n",
      "Batch 11000\n",
      "Batch 12000\n",
      "Batch 13000\n",
      "Batch 14000\n",
      "Batch 15000\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "print(len(validation_loader))\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(training_loader, 0):\n",
    "        # basic training loop\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # Every 1000 mini-batches...\n",
    "            print('Batch {}'.format(i + 1))\n",
    "            # Check against the validation set\n",
    "            running_vloss = 0.0\n",
    "\n",
    "            net.train(False) # Don't need to track gradents for validation\n",
    "            for j, vdata in enumerate(validation_loader, 0):\n",
    "                vinputs, vlabels = vdata\n",
    "                voutputs = net(vinputs)\n",
    "                vloss = criterion(voutputs, vlabels)\n",
    "                running_vloss += vloss.item()\n",
    "            net.train(True) # Turn gradients back on for training\n",
    "\n",
    "            avg_loss = running_loss / 1000\n",
    "            avg_vloss = running_vloss / len(validation_loader)\n",
    "\n",
    "            # Log the running loss averaged per batch\n",
    "            writer.add_scalars('Training vs. Validation Loss',\n",
    "                            { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                            epoch * len(training_loader) + i)\n",
    "\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, grab a single mini-batch of images\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# add_graph() will trace the sample input through your model,\n",
    "# and render it as a graph.\n",
    "writer.add_graph(net, images)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# Select a random subset of data and corresponding labels\n",
    "def select_n_random(data, labels, n=100):\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# Extract a random subset of data\n",
    "images, labels = select_n_random(training_set.data, training_set.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[label] for label in labels]\n",
    "\n",
    "# log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "                    metadata=class_labels,\n",
    "                    label_img=images.unsqueeze(1))\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(training_loader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(training_loader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(training_loader) + i)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. gets the probability predictions in a test_size x num_classes Tensor\n",
    "# 2. gets the preds in a test_size Tensor\n",
    "# takes ~10 seconds to run\n",
    "class_probs = []\n",
    "class_label = []\n",
    "with torch.no_grad():\n",
    "    for data in validation_loader:\n",
    "        images, labels = data\n",
    "        output = net(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_label.append(labels)\n",
    "\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_label = torch.cat(class_label)\n",
    "\n",
    "# helper function\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_label, global_step=0):\n",
    "    '''\n",
    "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
    "    precision-recall curve\n",
    "    '''\n",
    "    tensorboard_truth = test_label == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_truth,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "    writer.close()\n",
    "\n",
    "# plot all the pr curves\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
